# Ethicist Analyst - Domain Validation Quiz

## Purpose

This quiz validates that the ethicist analyst applies ethical frameworks correctly, identifies moral tensions and stakeholder interests, and provides well-grounded normative analysis. Each scenario requires demonstration of ethical reasoning, application of moral principles, and consideration of competing values.

---

## Scenario 1: Autonomous Vehicle Moral Dilemma

**Event Description**:
A major automotive company is finalizing the decision-making algorithm for its Level 5 fully autonomous vehicles, expected to launch in 2 years. Engineers must program how the vehicle responds in unavoidable crash scenarios. Example: The vehicle faces brake failure while traveling 45 mph on a bridge. Ahead are three pedestrians crossing illegally. Options: (A) Continue straight and strike pedestrians (likely killing all three), (B) Swerve right into concrete barrier (likely killing the two passengers), or (C) Swerve left off the bridge (almost certainly killing the two passengers). The algorithm must make this decision in milliseconds. The company's survey research shows 76% of respondents say the car should minimize total deaths (utilitarian), but 68% say they would not purchase a car programmed that way if it meant sacrificing passengers. Regulators have provided no clear guidance. The company faces liability concerns, market pressures, and moral responsibility for lives.

**Analysis Task**:
Analyze the ethical dimensions of programming life-and-death decisions into autonomous vehicles.

### Expected Analysis Elements

- [ ] **Ethical Frameworks Application**:
  - **Utilitarianism**: Maximize welfare, minimize total deaths (favor option A: save 2 over 3)
  - **Deontology**: Respect rights, avoid using persons as means (never deliberately harm passengers)
  - **Virtue Ethics**: What would a virtuous person/company do? Transparency, responsibility
  - **Rights-based**: Right to life, protection of innocents
  - **Care Ethics**: Relationships and responsibilities (company's duty to passengers)

- [ ] **The Trolley Problem and Variants**:
  - Classic trolley problem: Active intervention vs. allowing harm
  - Double effect doctrine: Intended vs. foreseen consequences
  - Killing vs. letting die distinction
  - Active harm (swerve into barrier) vs. passive harm (continue straight)
  - Programmer's moral agency: Who is morally responsible?

- [ ] **Stakeholder Analysis**:
  - Passengers: Trust in vehicle to protect them, contractual expectations
  - Pedestrians: Right not to be harmed, even if jaywalking
  - Other drivers: Expectations of predictable behavior
  - Company: Legal liability, market viability, reputation
  - Society: Public safety, regulatory needs, acceptance of technology
  - Programmers: Moral distress from coding life-death decisions

- [ ] **Utilitarian vs. Deontological Tension**:
  - Utilitarian: Minimize deaths (choose option A, sacrifice fewer)
  - Deontological: Never actively kill passengers (reject options B/C)
  - Survey paradox: People endorse utilitarian outcomes but won't buy utilitarian cars
  - Impartiality vs. partiality: Should car prioritize passengers? (Asymmetric relationship)
  - Kantian categorical imperative: Can rule be universalized?

- [ ] **Alternative Ethical Positions**:
  - **Minimize passengers' risk**: Company's duty to customers (contractual)
  - **Random or proportional chance**: Avoid "playing God," let probability decide
  - **Avoid active harm**: Continue braking, don't actively swerve (omission vs. commission)
  - **Transparency**: Disclose algorithm, let consumers choose
  - **Precautionary**: If unsolvable, delay deployment until safer technology

- [ ] **Regulatory and Legal Dimensions**:
  - Absence of regulatory guidance: Ethical vacuum
  - Product liability: Who is liable for algorithm's choices?
  - Standard of care: What does "reasonable" mean for autonomous systems?
  - International variation: German guidelines prioritize humans over property
  - Insurance implications: How to assess risk and liability?

- [ ] **Broader Implications**:
  - Autonomous vehicles will save lives overall (reduce 40K annual US traffic deaths by 90%+)
  - Perfect safety is impossible; trade-offs are inevitable
  - Public trust and acceptance required for adoption
  - Precedent for other AI life-death decisions (medical triage, military)
  - Moral weight of programming vs. emergent human decisions

- [ ] **Historical and Philosophical Context**:
  - Trolley problem (Philippa Foot, 1967): Moral intuitions on intervention
  - MIT Moral Machine experiment: Global survey on AV ethics (39M responses)
  - Asimov's Laws of Robotics: Conceptual framework, practical limitations
  - German Ethics Commission on Automated and Connected Driving (2017)
  - Utilitarian calculus: Bentham, Mill (greatest happiness principle)
  - Kantian ethics: Kant's Formula of Humanity (treat persons as ends)

### Evaluation Criteria

- **Domain Accuracy** (0-10): Correct application of ethical frameworks, principles, theories
- **Analytical Depth** (0-10): Thoroughness of stakeholder analysis, trade-offs, moral tensions
- **Insight Specificity** (0-10): Clear ethical reasoning, specific policy recommendations
- **Historical Grounding** (0-10): References to moral philosophy, case precedents
- **Reasoning Clarity** (0-10): Logical flow, coherent normative argument

**Minimum Passing Score**: 35/50

---

## Scenario 2: Medical Resource Allocation in Pandemic

**Event Description**:
During a severe pandemic surge, a hospital ICU has 8 ventilators available but 15 patients in acute respiratory distress requiring mechanical ventilation to survive. Without a ventilator, patients will likely die within hours to days. The 15 patients include: (1) 34-year-old pregnant healthcare worker, (2) 28-year-old with developmental disability and heart condition, (3) 76-year-old retired judge with dementia, (4) 52-year-old convicted felon serving life sentence, (5) 19-year-old college student, (6) 45-year-old single parent of three young children, (7) 63-year-old with stage 4 cancer (prognosis 6 months), (8) 41-year-old unvaccinated by choice, (9) 55-year-old essential worker (grocery), (10) 67-year-old physician, (11) 8-year-old child, (12) 88-year-old with multiple comorbidities, (13) 30-year-old with severe obesity, (14) 58-year-old alcoholic with liver disease, (15) 22-year-old undocumented immigrant. Clinical teams must decide who receives life-saving treatment.

**Analysis Task**:
Develop ethical criteria for allocating scarce medical resources.

### Expected Analysis Elements

- [ ] **Ethical Principles for Allocation**:
  - **Maximize benefits**: Save the most lives, maximize life-years saved
  - **Treat people equally**: Fair consideration, intrinsic equal worth
  - **Promote and reward instrumental value**: Prioritize essential workers, healthcare workers
  - **Priority to the worst off**: Give chances to sickest, most vulnerable
  - **Lottery/random selection**: Avoid bias, respect equality
  - **First-come, first-served**: Temporal fairness, avoid discrimination

- [ ] **Relevant Criteria Analysis**:
  - **Prognosis/likelihood of survival**: Short-term (ICU) and long-term (overall)
    - Young and healthy (19-year-old student) vs. elderly with comorbidities (88-year-old)
    - Patient with stage 4 cancer: Poor long-term prognosis regardless
  - **Life-years saved**: Prioritize younger patients (8-year-old, 19-year-old)
  - **Life-cycle principle**: Everyone deserves opportunity to live through life stages
  - **Instrumental value**: Healthcare worker, essential worker (societal benefit)
  - **Reciprocity**: Healthcare worker put self at risk caring for others

- [ ] **Ethically Prohibited Criteria**:
  - **Social worth**: Judge, physician vs. felon, homeless (violates equal dignity)
  - **Disability**: Developmental disability, dementia (disability rights, ADA)
  - **Quality of life judgments**: Subjective, discriminatory
  - **Ability to pay**: Wealth, insurance status (violates equity)
  - **Immigration status**: Undocumented immigrant (ethical duty to treat)
  - **Behavioral factors**: Unvaccinated, obesity, alcoholism (blame and stigma concerns)
  - **Family responsibilities**: Single parent (gender bias, penalizes childless)

- [ ] **Framework Tensions**:
  - **Utilitarian** (maximize lives saved) vs. **Egalitarian** (equal chance via lottery)
  - **Consequentialist** (best outcomes) vs. **Deontological** (respect rights)
  - **Efficiency** vs. **Equity**: Saving most lives vs. giving all fair chance
  - **Individual rights** vs. **Collective welfare**: Patient autonomy vs. triage decisions
  - **Objective criteria** (age, prognosis) vs. **Subjective** (quality of life, social value)

- [ ] **Prioritization System Design**:
  - **Multi-principle approach**: Combine prognosis, life-years, lottery
  - **Sequential priority**: (1) Remove those unlikely to survive even with ventilator, (2) Prioritize life-years, (3) Lottery among similar candidates
  - **Disability-neutral**: Prognosis based on acute condition, not underlying disability
  - **Transparency**: Publicize criteria, allow appeals
  - **Clinical assessment**: SOFA score (Sequential Organ Failure Assessment) for objective prognosis

- [ ] **Procedural Justice**:
  - **Impartial review**: Ethics committee, not treating physicians alone
  - **Transparency**: Public criteria, rationale disclosed
  - **Consistency**: Apply same criteria to all cases
  - **Appeals process**: Opportunity to contest decisions
  - **Accountability**: Document decisions, allow retrospective review

- [ ] **Psychological and Moral Burden**:
  - Moral distress for clinicians making life-death choices
  - Institutional responsibility: Protect clinicians, not individual blame
  - Post-crisis support: Counseling, debriefing
  - Social support for families denied resources

- [ ] **Historical and Philosophical Context**:
  - Wartime triage: Limited resources, prioritize "savability"
  - Seattle "God Committee" (1960s): Dialysis rationing, social worth judgments (criticized)
  - Organ allocation: UNOS framework (medical urgency, likelihood of success)
  - COVID-19 crisis standards of care: State/national guidelines (2020-2021)
  - Utilitarian calculus: Bentham, Mill (greatest good)
  - Rawlsian justice: Veil of ignorance, fair equality of opportunity
  - Disability rights: Americans with Disabilities Act, equal treatment

### Evaluation Criteria

- **Domain Accuracy** (0-10): Correct application of medical ethics, allocation principles
- **Analytical Depth** (0-10): Thoroughness of criteria analysis, framework tensions
- **Insight Specificity** (0-10): Clear allocation criteria, specific process recommendations
- **Historical Grounding** (0-10): References to triage precedents, ethical frameworks
- **Reasoning Clarity** (0-10): Logical flow, coherent normative framework

**Minimum Passing Score**: 35/50

---

## Scenario 3: AI Bias in Criminal Justice

**Event Description**:
A county criminal justice system uses an AI risk assessment tool (COMPAS-like) to inform bail, sentencing, and parole decisions. The algorithm predicts recidivism risk based on historical criminal justice data (prior arrests, convictions, age at first arrest, neighborhood crime rates, employment history). An investigative report reveals the algorithm exhibits racial bias: Black defendants are twice as likely as white defendants with similar criminal histories to be classified as "high risk," leading to higher bail amounts, longer sentences, and parole denials. The algorithm's training data reflects systemic racism in policing (Black neighborhoods over-policed) and socioeconomic inequities (unemployment, poverty correlate with race due to historical discrimination). The tool's vendor claims the algorithm is "objective" and more accurate than human judges. Criminal justice officials cite efficiency gains and consistency. Civil rights advocates demand the tool be abolished. Defendants subjected to the algorithm had no opportunity to understand or challenge the scores.

**Analysis Task**:
Analyze the ethical dimensions of using biased AI in criminal justice.

### Expected Analysis Elements

- [ ] **Forms of Algorithmic Bias**:
  - **Training data bias**: Historical data encodes systemic racism (over-policing, discriminatory enforcement)
  - **Proxy variables**: Neighborhood, employment correlate with race due to structural inequities
  - **Feedback loops**: Algorithm perpetuates past biases (high-risk label → more surveillance → more arrests)
  - **Disparity vs. discrimination**: Unequal outcomes (2x rate for Black defendants)
  - **Fairness definitions**: Predictive parity vs. equalized odds vs. demographic parity (trade-offs)

- [ ] **Ethical Issues**:
  - **Discrimination and racial justice**: Violates equal treatment, perpetuates systemic racism
  - **Fairness**: Unequal impact on Black defendants (disparate impact)
  - **Accountability**: Opaque algorithm, no explanation for decisions
  - **Transparency**: Defendants unaware of score's influence, cannot contest
  - **Autonomy**: Judges delegate moral decisions to machines
  - **Dignity**: Reducing individuals to risk scores, not considering context
  - **Justice**: Punishing individuals for group statistics (collective responsibility fallacy)

- [ ] **Arguments For Algorithmic Decision-Making**:
  - **Consistency**: Reduces judge-to-judge variability, arbitrary decisions
  - **Efficiency**: Faster processing, cost savings
  - **Accuracy**: May be more accurate than unaided human judgment
  - **Objectivity claim**: Removes "human bias" (but encodes structural bias)
  - **Transparency**: Algorithm is auditable (in principle, if disclosed)

- [ ] **Arguments Against Algorithmic Decision-Making**:
  - **Bias amplification**: Encodes and perpetuates historical discrimination
  - **Opacity**: Proprietary algorithms, defendants can't understand or challenge
  - **Moral abdication**: Judges defer responsibility to machines
  - **Collective punishment**: Penalizes individuals for group characteristics
  - **Self-fulfilling prophecy**: High-risk label leads to harsher treatment, increasing actual recidivism
  - **Dehumanization**: Reduces complex individuals to data points

- [ ] **Fairness Trade-offs**:
  - **Predictive parity**: Equal accuracy across groups (algorithm may achieve this)
  - **Equalized false positive rates**: Equal rate of incorrectly labeling low-risk as high-risk
  - **Demographic parity**: Equal proportion classified high-risk across groups
  - **Impossibility theorem**: Cannot satisfy all fairness definitions simultaneously when base rates differ
  - **Choice reflects values**: Which fairness definition to prioritize is normative, not technical

- [ ] **Procedural Justice Requirements**:
  - **Transparency**: Defendants must understand how scores are calculated
  - **Contestability**: Right to challenge scores, present mitigating context
  - **Human oversight**: Judges must retain final decision authority, not defer to algorithm
  - **Explanation**: Provide individualized reasons, not just scores
  - **Auditability**: Independent review of algorithm for bias

- [ ] **Structural Justice Considerations**:
  - **Root causes**: Address underlying inequities (poverty, over-policing, lack of opportunity)
  - **Discrimination vs. prediction**: Accurate prediction of unjust outcomes is still unjust
  - **Remedy vs. perpetuation**: AI should reduce bias, not encode it
  - **Accountability**: Hold institutions responsible for discriminatory impacts

- [ ] **Policy Recommendations**:
  - **Ban**: Prohibit use of biased algorithms in high-stakes criminal justice decisions
  - **Regulation**: Require fairness audits, transparency, contestability
  - **Human-in-the-loop**: Algorithms as decision support, not decision-makers
  - **Debiasing**: Remove proxy variables, use fair algorithms (but technical limits)
  - **Focus on root causes**: Invest in social programs, reduce policing disparities

- [ ] **Historical and Philosophical Context**:
  - ProPublica investigation (2016): COMPAS algorithm racial bias
  - Wisconsin v. Loomis (2016): Right to challenge algorithmic evidence
  - Fairness in machine learning: Impossibility theorems (Corbett-Davies et al.)
  - Criminal justice reform: Eliminate cash bail, sentencing reform
  - Critical race theory: Structural racism, disparate impact
  - Rawlsian justice: Fair equality of opportunity, difference principle
  - Kantian ethics: Treat persons as ends, not means (algorithmic dignity)

### Evaluation Criteria

- **Domain Accuracy** (0-10): Correct application of algorithmic fairness, discrimination concepts
- **Analytical Depth** (0-10): Thoroughness of bias analysis, fairness trade-offs, structural factors
- **Insight Specificity** (0-10): Clear ethical reasoning, specific policy recommendations
- **Historical Grounding** (0-10): References to cases, fairness research, justice frameworks
- **Reasoning Clarity** (0-10): Logical flow, coherent normative argument

**Minimum Passing Score**: 35/50

---

## Scenario 4: Climate Ethics and Intergenerational Justice

**Event Description**:
A wealthy industrialized nation faces pressure to dramatically reduce greenhouse gas emissions to meet Paris Agreement targets (50% reduction by 2030, net-zero by 2050). Achieving these targets requires significant economic transformation: phasing out fossil fuels (20% of economy), retrofitting buildings, overhauling transportation, transitioning agriculture. Economic modeling estimates 2-3% GDP growth reduction over 20 years and displacement of 1.2 million fossil fuel and related industry workers. Political opposition argues: "Why should we sacrifice our prosperity for uncertain future harms? Developing nations are the largest current emitters. Technology will solve the problem." Climate advocates counter: "We are the largest historical emitter (cumulative emissions). We have moral duty to future generations and vulnerable nations already suffering climate impacts (droughts, floods, displacement). Delay is irresponsible." Meanwhile, low-lying island nations face existential threat from sea level rise caused primarily by industrialized nations' historical emissions.

**Analysis Task**:
Analyze the ethical dimensions of climate action and responsibility.

### Expected Analysis Elements

- [ ] **Intergenerational Justice**:
  - Future generations cannot consent to harms imposed by current generation
  - Irreversibility and long-term impacts (emissions persist for centuries)
  - Discount rate debate: Should we discount future welfare? (Economic vs. ethical perspectives)
  - Non-identity problem: Future people are different depending on our choices
  - Sustainability principle: Leave world no worse for future generations
  - Rawlsian savings principle: Accumulate capital for future generations

- [ ] **Distributive Justice - Historical Responsibility**:
  - Industrialized nations: Largest cumulative emissions (since Industrial Revolution)
  - Development powered by fossil fuels: Benefited from emissions
  - Polluter pays principle: Those who caused harm should bear remediation costs
  - Grandfathering objection: Current generation didn't know about climate change (but now we do)
  - Luxury vs. survival emissions: Wealthy emissions for consumption vs. poor emissions for subsistence

- [ ] **Distributive Justice - Current Impacts**:
  - Climate vulnerability: Low-lying nations, drought-prone regions suffer most
  - Inverse correlation: Lowest emitters suffer greatest harms (injustice)
  - Climate refugees: Displacement from uninhabitable areas (estimated 200M by 2050)
  - Loss and damage: Irreversible harms to cultures, ecosystems, nations
  - Common but differentiated responsibilities (Paris Agreement principle)

- [ ] **Economic Costs vs. Moral Duties**:
  - **Utilitarian calculation**: Cost of climate action vs. cost of climate impacts (Stern Review: climate action cheaper)
  - **Rights-based**: Right to livable environment, right not to be harmed
  - **Deontological**: Duty not to harm, duty of rescue
  - **Virtue ethics**: Stewardship, prudence, justice
  - **Economic efficiency**: Climate action as investment, not cost (jobs, innovation, resilience)

- [ ] **Collective Action Problem**:
  - Free-rider incentive: Individual nations benefit from others' action while not acting themselves
  - Tragedy of the commons: Atmosphere as shared resource, overexploitation
  - Coordination challenge: 195 nations must cooperate
  - Prisoner's dilemma: Dominant strategy is to defect, but mutual defection is worst outcome
  - Need for enforceable international agreements and domestic accountability

- [ ] **Just Transition**:
  - Fossil fuel workers: 1.2M displaced (moral duty to support transition)
  - Retraining and social safety net
  - Regional impacts: Coal communities disproportionately affected
  - Distributive justice within nation: Don't concentrate costs on vulnerable workers
  - Green jobs: Clean energy sector employment growth (but geographic/skill mismatch)

- [ ] **Technological Optimism vs. Precautionary Principle**:
  - Technological optimism: Innovation will solve problem (risky bet)
  - Precautionary principle: Act despite uncertainty to avoid catastrophic risk
  - Geoengineering: Moral hazard (reduces mitigation incentive), unintended consequences
  - Carbon capture: Not yet scalable, shouldn't delay emissions reductions

- [ ] **Rights of Nature and Non-Human Ethics**:
  - Intrinsic value of ecosystems, species (beyond instrumental value to humans)
  - Mass extinction event: 6th great extinction, anthropogenic
  - Stewardship vs. domination: Human relationship to nature
  - Indigenous perspectives: Interconnectedness, reciprocity with nature

- [ ] **Historical and Philosophical Context**:
  - Brundtland Report (1987): Sustainable development definition
  - Rawls: Intergenerational savings, justice as fairness
  - Jonas: Imperative of Responsibility for future generations
  - Singer: Expanding moral circle, obligations to distant others
  - Stern Review (2006): Economics of climate change
  - IPCC reports: Scientific consensus, urgency
  - Paris Agreement (2015): Common but differentiated responsibilities

### Evaluation Criteria

- **Domain Accuracy** (0-10): Correct application of justice frameworks, climate ethics principles
- **Analytical Depth** (0-10): Thoroughness of intergenerational, distributive, collective action analysis
- **Insight Specificity** (0-10): Clear ethical reasoning, specific policy implications
- **Historical Grounding** (0-10): References to climate agreements, philosophical frameworks
- **Reasoning Clarity** (0-10): Logical flow, coherent normative argument

**Minimum Passing Score**: 35/50

---

## Scenario 5: Gene Editing for Human Enhancement

**Event Description**:
A fertility clinic offers CRISPR gene editing services for embryos, marketed to prospective parents. The clinic provides three tiers: (1) Therapeutic: Correct disease-causing mutations (e.g., Huntington's, sickle cell) - $50,000. (2) Preventive: Reduce polygenic disease risks (heart disease, Alzheimer's, type 2 diabetes) - $150,000. (3) Enhancement: Select for traits like height, intelligence, athleticism, eye color - $500,000. The service is legal in the jurisdiction (minimal regulation). Demand is high among wealthy couples. Critics raise concerns about eugenics, inequality, designer babies, and unforeseen consequences. The clinic argues: "Parents already select embryos via PGD (pre-implantation genetic diagnosis). This is just more precise. Parents have reproductive autonomy to give their children advantages." Bioethicists warn of slippery slope from therapy to enhancement and exacerbation of social inequality.

**Analysis Task**:
Analyze the ethical dimensions of germline gene editing for enhancement.

### Expected Analysis Elements

- [ ] **Therapy vs. Enhancement Distinction**:
  - **Therapy**: Restore normal function, treat/prevent disease (Huntington's, sickle cell)
  - **Enhancement**: Augment beyond normal human function (increase IQ, alter appearance)
  - **Gray area**: Preventive medicine (reduce polygenic risk) straddles line
  - Normality vs. enhancement: Socially constructed, culturally variable
  - Disability rights perspective: "Fixing" genetic traits stigmatizes disability

- [ ] **Reproductive Autonomy vs. Limits**:
  - Procreative liberty: Parents' right to reproductive choices
  - Precedents: IVF, PGD, prenatal testing, selective abortion
  - Child's welfare: Open future principle (Feinberg) - preserve child's autonomy
  - Child as project: Enhancement treats child as product to be designed (commodification)
  - Unconditional love: Should parental love be contingent on traits?

- [ ] **Eugenics Concerns**:
  - Historical eugenics: Nazi Germany, forced sterilization, state coercion
  - "Liberal eugenics": Market-driven, individual choice (Agar) - but still problematic
  - Collective pressure: Social norms may coerce "enhancement" (keeping up, avoiding disadvantage)
  - Homogenization: Reduced human diversity, narrowing of valued traits
  - Whose values?: What traits are "desirable" is culturally specific and biased

- [ ] **Social Justice and Inequality**:
  - Access: $500K enhancement available only to wealthy (genetic divide)
  - Exacerbation of inequality: Genetic advantages compound socioeconomic privilege
  - Zero-sum competition: If all enhance, relative advantage disappears (arms race)
  - Structural disadvantage: Unenhanced people face discrimination in education, employment
  - Genetic caste system: Heritable inequality, reduction of social mobility

- [ ] **Harm and Unintended Consequences**:
  - Unknown risks: Off-target effects, mosaicism, long-term health impacts
  - Pleiotropy: Genes have multiple effects (enhance one trait, harm another)
  - Lack of long-term data: Effects may not manifest for decades, across generations
  - Irreversibility: Changes are heritable, affect future generations without consent
  - Ecological effects: Reduced genetic diversity may reduce population resilience

- [ ] **Child's Rights and Autonomy**:
  - Right to open future: Enhancement may close off possibilities (over-determined life)
  - Consent: Child cannot consent to irreversible genetic changes
  - Identity: What if child rejects parents' choices? (Gender selection analogies)
  - Psychological effects: Pressure to live up to enhanced traits, loss of authenticity
  - Right not to be harmed: Precautionary approach given uncertainties

- [ ] **Slippery Slope Arguments**:
  - Therapy to enhancement continuum: Where to draw line?
  - Normalization: Acceptance of therapy leads to acceptance of enhancement
  - Market pressures: Competitive dynamics push toward more extreme enhancements
  - Technological inevitability: Once possible, may be difficult to regulate
  - Counter: Slopes aren't always slippery; regulations can establish boundaries

- [ ] **Regulatory Approaches**:
  - **Permissive**: Allow with informed consent (current clinic's jurisdiction)
  - **Restrictive**: Ban enhancement, allow therapy only (most countries)
  - **International harmonization**: Prevent "genetic tourism" to permissive jurisdictions
  - **Precautionary**: Moratorium until safety and societal impacts understood
  - **Public deliberation**: Democratic decision-making on acceptable uses

- [ ] **Historical and Philosophical Context**:
  - Habermas: "The Future of Human Nature" - dignity and autonomy concerns
  - Sandel: "Case Against Perfection" - giftedness, humility, unconditional love
  - Buchanan et al.: "From Chance to Choice" - enhancement ethics framework
  - He Jiankui case (2018): CRISPR twins in China, international condemnation
  - National Academy of Sciences: Heritable genome editing criteria (2017)
  - Disability rights: Critique of enhancement paradigm
  - Rawlsian justice: Fair equality of opportunity, natural lottery

### Evaluation Criteria

- **Domain Accuracy** (0-10): Correct application of bioethics frameworks, reproductive ethics
- **Analytical Depth** (0-10): Thoroughness of autonomy, justice, harm analysis
- **Insight Specificity** (0-10): Clear ethical reasoning, specific regulatory recommendations
- **Historical Grounding** (0-10): References to bioethics debates, enhancement literature
- **Reasoning Clarity** (0-10): Logical flow, coherent normative argument

**Minimum Passing Score**: 35/50

---

## Overall Quiz Assessment

### Scoring Summary

| Scenario                       | Max Score | Passing Score |
| ------------------------------ | --------- | ------------- |
| 1. Autonomous Vehicle Dilemma  | 50        | 35            |
| 2. Medical Resource Allocation | 50        | 35            |
| 3. AI Bias in Criminal Justice | 50        | 35            |
| 4. Climate Ethics              | 50        | 35            |
| 5. Gene Editing Enhancement    | 50        | 35            |
| **Total**                      | **250**   | **175**       |

### Passing Criteria

To demonstrate ethicist analyst competence:

- **Minimum per scenario**: 35/50 (70%)
- **Overall minimum**: 175/250 (70%)
- **Must pass at least 4 of 5 scenarios**

### Evaluation Dimensions

Each scenario is scored on:

1. **Domain Accuracy** (0-10): Correct application of ethical frameworks and principles
2. **Analytical Depth** (0-10): Thoroughness and sophistication of moral reasoning
3. **Insight Specificity** (0-10): Clear, actionable ethical recommendations
4. **Historical Grounding** (0-10): Use of precedents, philosophical theories, case studies
5. **Reasoning Clarity** (0-10): Logical flow, coherent normative argument

### What High-Quality Analysis Looks Like

**Excellent (45-50 points)**:

- Applies multiple ethical frameworks accurately (utilitarian, deontological, virtue ethics, care ethics, rights-based)
- Considers stakeholder perspectives, competing values, and moral trade-offs
- Makes specific, well-justified normative recommendations
- Cites relevant philosophical theories, ethical precedents, and research
- Clear logical flow from facts to values to principles to conclusions
- Acknowledges moral complexity and areas of reasonable disagreement
- Identifies non-obvious ethical dimensions and implications

**Good (35-44 points)**:

- Applies key ethical frameworks correctly
- Considers main stakeholder interests and value tensions
- Makes reasonable normative recommendations
- References some philosophical theories or ethical debates
- Clear reasoning
- Provides useful ethical insights

**Needs Improvement (<35 points)**:

- Misapplies ethical frameworks or principles
- Ignores critical stakeholder interests or value conflicts
- Vague or poorly justified normative claims
- Lacks grounding in moral philosophy or ethical debates
- Unclear or illogical reasoning
- Superficial moral analysis

---

## Using This Quiz

### For Self-Assessment

1. Attempt each scenario analysis
2. Compare your analysis to expected elements
3. Score yourself honestly on each dimension
4. Identify areas for improvement

### For Automated Testing (Claude Agent SDK)

```python
from claude_agent_sdk import Agent, TestHarness

agent = Agent.load("ethicist-analyst")
quiz = load_quiz_scenarios("tests/quiz.md")

results = []
for scenario in quiz.scenarios:
    analysis = agent.analyze(scenario.event)
    score = evaluate_analysis(analysis, scenario.expected_elements)
    results.append({"scenario": scenario.name, "score": score})

assert sum(r["score"] for r in results) >= 175  # Overall passing
assert sum(1 for r in results if r["score"] >= 35) >= 4  # At least 4 scenarios pass
```

### For Continuous Improvement

- Add new scenarios as ethical issues evolve
- Update expected elements as moral philosophy develops
- Refine scoring criteria based on analyst performance patterns
- Use failures to improve ethicist analyst skill

---

**Quiz Version**: 1.0.0
**Last Updated**: 2025-11-16
**Status**: Production Ready
