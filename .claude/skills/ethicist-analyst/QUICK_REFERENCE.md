# Ethicist Analyst - Quick Reference

## TL;DR

Analyzes moral dimensions through ethical frameworks using deontology, consequentialism, virtue ethics, care ethics, and justice theory. Provides rigorous justification for ethical decisions with stakeholder analysis and value trade-offs made explicit.

## When to Use

- Ethical dilemmas with conflicting values
- Technology ethics (AI, biotech, privacy)
- Professional ethics (medical, legal, business, research)
- Policy fairness and justice
- Rights violations and moral obligations
- Organizational ethics and stakeholder conflicts

## Core Frameworks

1. **Deontology (Kant)** - Duty-based; respect persons as ends, not means
2. **Consequentialism (Mill)** - Outcome-based; maximize overall well-being
3. **Virtue Ethics (Aristotle)** - Character-based; what would virtuous person do?
4. **Care Ethics (Gilligan)** - Relational; responsibilities from relationships
5. **Justice Theory (Rawls)** - Fairness; veil of ignorance, difference principle

## Theoretical Foundations

- **Deontology**: Categorical imperative, rights, duties, respect for persons
- **Consequentialism**: Utilitarianism, effective altruism, maximize utility
- **Virtue Ethics**: Character, phronesis, eudaimonia, moral exemplars
- **Justice**: Distributive justice, procedural fairness, social contract
- **Care Ethics**: Vulnerability, relationships, context-sensitivity

## Quick Analysis Process

1. **Clarify Issue** - What is the moral question? Why ethical?
2. **Gather Facts** - Verify claims, identify alternatives
3. **Identify Stakeholders** - Who's affected? Interests? Vulnerabilities?
4. **Articulate Conflicts** - Which values/rights/principles in tension?
5. **Apply Frameworks** - Use deontology, consequentialism, virtue, care, justice
6. **Test Consistency** - Would same reasoning apply to similar cases?
7. **Consider Alternatives** - Engage counterarguments, diverse views
8. **Assess Constraints** - Legal, political, resource limits
9. **Reach Equilibrium** - Construct coherent justification
10. **Communicate** - Present reasoning, acknowledge trade-offs

## Key Questions

**Deontological**:

- What duties or rights are at stake?
- Can I universalize this action without contradiction?
- Am I treating anyone merely as means to an end?
- What does respect for persons require?

**Consequentialist**:

- What are likely consequences for all affected?
- Which option maximizes overall well-being?
- Have I considered long-term and systemic effects?
- Am I weighing everyone's interests equally?

**Virtue Ethics**:

- What would a virtuous person do in this situation?
- What character traits are relevant (courage, honesty, wisdom)?
- What kind of person will I become through this choice?
- Who are moral exemplars I can learn from?

**Care Ethics**:

- What do my relationships require?
- Who is vulnerable and needs care?
- Am I attending to particular context and needs?
- Are power dynamics affecting the situation?

**Justice**:

- Is this distribution of benefits/burdens fair?
- Would I choose this behind veil of ignorance?
- Does this respect equal dignity of all persons?
- Are procedures impartial and transparent?

## Applied Frameworks

**Four Principles (Bioethics)**:

1. Autonomy - Respect self-determination
2. Beneficence - Promote well-being
3. Non-maleficence - Avoid harm
4. Justice - Fair distribution

**Stakeholder Analysis**:

- List all affected parties
- Identify interests and rights
- Assess power and vulnerability
- Weigh conflicts

**Double Effect**:

- Act itself must be good/neutral
- Good effect intended, bad merely foreseen
- Bad not means to good
- Proportionality: good outweighs bad

**Casuistry**:

- Identify paradigm cases (clear moral judgments)
- Extract relevant features
- Compare new case to paradigm
- Adjust reasoning for differences

## Common Mistakes to Avoid

- **Relativism**: "It's all subjective" prevents reasoning
- **Appeal to emotion**: Feelings don't settle questions
- **Appeal to authority**: Law/experts inform but don't determine ethics
- **False dichotomy**: Binary framing when multiple options exist
- **Slippery slope**: Requires showing actual causal connection
- **Is-ought fallacy**: Can't infer "ought" from "is"
- **Naturalistic fallacy**: "Natural" ≠ "good"
- **Ad hominem**: Attack argument, not person
- **Paralysis**: Complexity shouldn't prevent taking position
- **Overconfidence**: Humility warranted in ethical reasoning

## Essential Resources

**Online Philosophy**:

- **Stanford Encyclopedia**: https://plato.stanford.edu/ (Comprehensive)
- **Internet Encyclopedia**: https://iep.utm.edu/ (Accessible)
- **1000-Word Philosophy**: https://1000wordphilosophy.com/ (Concise)

**Ethics Centers**:

- **Markkula Center**: https://www.scu.edu/ethics/ (Tools & cases)
- **Prindle Institute**: https://www.prindleinstitute.org/ (Blog & resources)

**Professional Organizations**:

- **APA**: https://www.apaonline.org/ (American Philosophical Association)
- **APPE**: https://appe.indiana.edu/ (Applied ethics)
- **Hastings Center**: https://www.thehastingscenter.org/ (Bioethics)

## Decision Heuristics

**When to prioritize which framework:**

**Deontology** when:

- Rights violations at stake
- Professional duties involved
- Respect for persons central
- Some acts seem wrong regardless of consequences

**Consequentialism** when:

- Policy design affecting large populations
- Resource allocation decisions
- Risk-benefit analysis needed
- Aggregate welfare paramount

**Virtue Ethics** when:

- Professional character formation
- Leadership and role modeling
- Novel situations requiring judgment
- Long-term character development

**Care Ethics** when:

- Caregiving relationships central
- Vulnerability and dependency
- Healthcare and family ethics
- Power asymmetries present

**Justice** when:

- Distributive fairness at issue
- Institutional design
- Systemic inequality
- Procedural fairness

## Key Principles

**Categorical Imperative (Kant)**:

- Act only on maxims you could will as universal law
- Treat humanity as end, never merely as means

**Utility Principle (Mill)**:

- Actions right in proportion to tendency to promote happiness
- Greatest happiness for greatest number

**Difference Principle (Rawls)**:

- Inequalities permitted only if they benefit worst-off
- Fair equality of opportunity

**Golden Rule**:

- Do unto others as you would have them do unto you
- (Found across cultures and traditions)

**Harm Principle (Mill)**:

- Only justify restricting liberty to prevent harm to others
- Self-regarding actions should be free

## Success Criteria

✓ Ethical question clearly stated
✓ Facts verified, alternatives identified
✓ All stakeholders considered (including vulnerable)
✓ Multiple frameworks applied systematically
✓ Logical reasoning, not mere intuition
✓ Consistency tested across similar cases
✓ Strongest counterarguments engaged
✓ Value trade-offs explicitly acknowledged
✓ Practical recommendations provided
✓ Limitations and uncertainties noted

## Framework Selection Guide

| Issue Type            | Primary Framework(s)         |
| --------------------- | ---------------------------- |
| Rights violations     | Deontology, Justice          |
| Resource allocation   | Consequentialism, Justice    |
| Professional conduct  | Virtue Ethics, Deontology    |
| Caregiving            | Care Ethics, Virtue          |
| Policy design         | Consequentialism, Justice    |
| Technology ethics     | All frameworks (pluralistic) |
| Organizational ethics | Stakeholder analysis, Virtue |

## Classic Thought Experiments

**Trolley Problem**: Reveals intuitions about doing vs. allowing harm, using people as means

**Veil of Ignorance**: Ensures impartiality by bracketing self-interest in justice reasoning

**Ring of Gyges**: Tests whether morality depends on reputation/punishment or has intrinsic value

**Experience Machine**: Tests whether well-being is only pleasure or includes reality/achievement

**Transplant Case**: Intuition against killing one to save five (deontological constraint)

---

**For full details, see SKILL.md**
