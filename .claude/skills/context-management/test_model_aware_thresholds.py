#!/usr/bin/env python3
"""Test model-aware threshold selection."""

import sys
from pathlib import Path

# Setup paths
sys.path.insert(0, str(Path(__file__).parent.parent))

from context_management import TokenMonitor


def test_model_aware_thresholds():
    """Test that thresholds adjust based on model size."""

    print("=" * 70)
    print("ðŸ§ª Testing Model-Aware Thresholds")
    print("=" * 70)

    # Test 1M token model (Sonnet 4.5)
    print("\nðŸ“Š Test 1: Sonnet 4.5 (1M tokens)")
    print("-" * 70)
    monitor_1m = TokenMonitor(max_tokens=1_000_000)
    print(f"Max tokens: {monitor_1m.max_tokens:,}")
    print(f"Thresholds: {monitor_1m.thresholds}")

    test_cases_1m = [
        (100_000, "ok"),  # 10% â†’ ok
        (250_000, "ok"),  # 25% â†’ ok
        (350_000, "consider"),  # 35% â†’ consider
        (450_000, "recommended"),  # 45% â†’ recommended
        (550_000, "urgent"),  # 55% â†’ urgent
    ]

    print("\nThreshold verification:")
    for tokens, expected in test_cases_1m:
        usage = monitor_1m.check_usage(tokens)
        status = usage.threshold_status
        match = "âœ…" if status == expected else "âŒ"
        print(
            f"  {match} {tokens:>7,} tokens ({tokens / 10_000:.0f}%) â†’ {status:>12} (expected: {expected})"
        )

    # Test 200k token model (Haiku)
    print("\nðŸ“Š Test 2: Haiku (200k tokens)")
    print("-" * 70)
    monitor_200k = TokenMonitor(max_tokens=200_000)
    print(f"Max tokens: {monitor_200k.max_tokens:,}")
    print(f"Thresholds: {monitor_200k.thresholds}")

    test_cases_200k = [
        (50_000, "ok"),  # 25% â†’ ok
        (90_000, "ok"),  # 45% â†’ ok
        (115_000, "consider"),  # 57.5% â†’ consider
        (145_000, "recommended"),  # 72.5% â†’ recommended
        (175_000, "urgent"),  # 87.5% â†’ urgent
    ]

    print("\nThreshold verification:")
    for tokens, expected in test_cases_200k:
        usage = monitor_200k.check_usage(tokens)
        status = usage.threshold_status
        match = "âœ…" if status == expected else "âŒ"
        print(
            f"  {match} {tokens:>7,} tokens ({(tokens / 200_000) * 100:.0f}%) â†’ {status:>12} (expected: {expected})"
        )

    print("\n" + "=" * 70)
    print("ðŸŽ¯ Model-Aware Thresholds Summary")
    print("=" * 70)

    print("\n1M Token Model (Sonnet 4.5):")
    print("  â€¢ Top threshold: 50% (500k tokens)")
    print("  â€¢ Auto-snapshots at: 30%, 40%, 50%")
    print("  â€¢ Philosophy: Conservative (plenty of space)")

    print("\n200k Token Model (Haiku):")
    print("  â€¢ Top threshold: 85% (170k tokens)")
    print("  â€¢ Auto-snapshots at: 55%, 70%, 85%")
    print("  â€¢ Philosophy: Aggressive (limited space)")

    print("\nâœ… Model-aware thresholds working correctly!")


if __name__ == "__main__":
    test_model_aware_thresholds()
