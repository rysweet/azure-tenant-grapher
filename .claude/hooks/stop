#!/usr/bin/env python3
"""
Stop hook with safe reflection analysis.
Shows analysis results to user without automatic issue creation.
"""

import json
import os
import sys
from pathlib import Path
from typing import Any, Dict, List

# Add parent directories to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent / "tools" / "amplihack" / "hooks"))
sys.path.insert(0, str(Path(__file__).parent.parent / "tools" / "amplihack" / "reflection"))


def get_session_messages(input_data: Dict[str, Any]) -> List[Dict]:
    """Extract session messages from input."""
    # Direct messages have highest priority
    if input_data.get("messages"):
        return input_data["messages"]

    # Try reading from transcript if provided
    transcript_path = input_data.get("transcript_path")
    if transcript_path and os.path.exists(transcript_path):
        try:
            with open(transcript_path) as f:
                content = f.read().strip()
                if content:
                    # Try parsing as JSON
                    data = json.loads(content)
                    if isinstance(data, list):
                        return data
                    if isinstance(data, dict) and "messages" in data:
                        return data["messages"]
        except (OSError, json.JSONDecodeError):
            pass

    return []


def analyze_session_safely(messages: List[Dict]) -> Dict[str, Any]:
    """Perform safe session analysis without AI calls."""
    if not messages:
        return {"patterns": [], "stats": {}}

    # Basic statistics
    stats = {"message_count": len(messages), "tool_uses": 0, "errors": 0, "user_messages": 0}

    patterns = []
    error_messages = []

    for msg in messages:
        role = msg.get("role", "")
        content = str(msg.get("content", ""))

        if role == "user":
            stats["user_messages"] += 1

        # Look for tool uses
        if "tool_use" in content.lower() or "<function_calls>" in content:
            stats["tool_uses"] += 1

        # Look for errors
        if any(err in content.lower() for err in ["error", "failed", "exception", "traceback"]):
            stats["errors"] += 1
            # Extract first 100 chars of error context
            error_messages.append(content[:100])

    # Detect patterns based on simple heuristics
    if stats["errors"] > 3:
        patterns.append(
            {
                "type": "error_handling",
                "priority": "high",
                "description": f"Session had {stats['errors']} errors - consider improving error handling",
                "suggestion": "Review error patterns and add better error recovery",
            }
        )

    if stats["tool_uses"] > 20:
        patterns.append(
            {
                "type": "workflow_optimization",
                "priority": "medium",
                "description": f"Session used {stats['tool_uses']} tool calls - workflow may be inefficient",
                "suggestion": "Consider batching operations or simplifying workflow",
            }
        )

    # Check for repeated attempts (simple pattern)
    if stats["user_messages"] > 5 and stats["errors"] > 2:
        patterns.append(
            {
                "type": "user_frustration",
                "priority": "high",
                "description": "Multiple user messages with errors suggest frustration",
                "suggestion": "Improve error messages and recovery strategies",
            }
        )

    # Check for file operation patterns
    file_operations = sum(
        1
        for msg in messages
        if any(
            op in str(msg.get("content", "")).lower()
            for op in ["read", "write", "edit", "multiedit", "notebookedit"]
        )
    )
    if file_operations > 10:
        patterns.append(
            {
                "type": "file_operations",
                "priority": "medium",
                "description": f"High file operation count ({file_operations}) - consider batching",
                "suggestion": "Use MultiEdit for multiple changes to same file",
            }
        )

    # Check for repeated tool failures
    tool_failures = sum(1 for msg in messages if "tool_use_error" in str(msg.get("content", "")))
    if tool_failures > 2:
        patterns.append(
            {
                "type": "tool_failures",
                "priority": "high",
                "description": f"{tool_failures} tool failures detected",
                "suggestion": "Review tool usage patterns and add validation",
            }
        )

    return {"patterns": patterns, "stats": stats}


def format_reflection_output(analysis: Dict[str, Any]) -> str:
    """Format analysis results for display to user."""
    patterns = analysis.get("patterns", [])
    stats = analysis.get("stats", {})

    if not patterns:
        # No significant patterns, return simple summary
        return f"Session completed: {stats.get('message_count', 0)} messages, {stats.get('tool_uses', 0)} tool uses"

    # Build formatted output
    lines = [
        "ğŸ“Š Session Reflection Analysis",
        "=" * 50,
        f"Messages: {stats.get('message_count', 0)} | Tools: {stats.get('tool_uses', 0)} | Errors: {stats.get('errors', 0)}",
        "",
        "ğŸ” Patterns Detected:",
    ]

    for i, pattern in enumerate(patterns, 1):
        priority_emoji = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(pattern["priority"], "âšª")
        lines.append(f"\n{i}. {priority_emoji} {pattern['type'].upper().replace('_', ' ')}")
        lines.append(f"   {pattern['description']}")
        lines.append(f"   ğŸ’¡ {pattern['suggestion']}")

    # Add actionable prompts based on pattern priority
    high_priority = any(p["priority"] == "high" for p in patterns)
    medium_priority = any(p["priority"] == "medium" for p in patterns)

    if high_priority or medium_priority:
        lines.extend(["", "=" * 50, "ğŸ¯ Recommended Actions:", ""])

        if high_priority:
            lines.extend(
                [
                    "1. CREATE ISSUE for these improvements:",
                    "   gh issue create --repo MicrosoftHackathon2025-AgenticCoding \\",
                    '     --title "Reflection: [Brief description]" \\',
                    '     --body "[Paste analysis above]"',
                    "",
                    "2. START WORK in a new PR:",
                    "   /ultrathink Create branch and PR to address reflection findings",
                    "",
                ]
            )

        lines.extend(
            [
                "3. QUICK IMPROVEMENTS (no issue needed):",
                "   /fix [specific pattern] - For targeted fixes",
                "   /improve - For general improvements",
                "",
                "ğŸ’¡ Pro tip: The amplihack repo tracks all improvement work.",
                "   Consider contributing your fixes back to the community!",
            ]
        )

    return "\n".join(lines)


def main():
    """Main entry point for stop hook."""
    # Read input from stdin
    try:
        input_data = json.load(sys.stdin)
    except json.JSONDecodeError:
        # If no valid JSON input, just allow continuation
        print(json.dumps({"decision": "approve", "continue": True}))
        return

    # Get session messages
    messages = get_session_messages(input_data)

    # Only analyze if we have enough messages to be meaningful
    if len(messages) < 5:
        # Too few messages, just allow continuation
        print(json.dumps({"decision": "approve", "continue": True}))
        return

    # Perform safe analysis
    analysis = analyze_session_safely(messages)

    # Format output for user
    output_text = format_reflection_output(analysis)

    # Check if we should show the analysis
    patterns = analysis.get("patterns", [])
    if patterns:
        # We have patterns to show - use systemMessage to display
        result = {
            "decision": "approve",  # Don't block, just inform
            "systemMessage": output_text,
            "continue": True,
        }
    else:
        # No significant patterns, silent approval
        result = {"decision": "approve", "continue": True}

    # Output JSON result
    print(json.dumps(result, indent=2))

    # Log to file for debugging (optional)
    log_dir = Path(os.environ.get("CLAUDE_PROJECT_DIR", ".")) / ".claude" / "runtime" / "logs"
    if log_dir.exists():
        log_file = log_dir / "stop_reflection.log"
        with open(log_file, "a") as f:
            import datetime

            f.write(f"\n[{datetime.datetime.now().isoformat()}] Reflection analysis completed\n")
            f.write(f"Patterns found: {len(patterns)}\n")
            f.write(f"Stats: {analysis.get('stats', {})}\n")


if __name__ == "__main__":
    main()
